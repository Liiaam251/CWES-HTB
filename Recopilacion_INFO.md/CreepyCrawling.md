# Bichos espeluznantes üï∑Ô∏è ‚Äî Rastreo web paso a paso (para novatos)

## 1) ¬øQu√© es el ‚Äúrastreo web‚Äù?
‚ÄúRastrear‚Äù una web es **visitar autom√°ticamente** sus p√°ginas para **descubrir enlaces, archivos e informaci√≥n p√∫blica** (como im√°genes, PDFs, scripts, etc.) y guardarlo ordenado para analizarlo despu√©s.

- **No es hacking** por s√≠ mismo: solo **lee contenido p√∫blico**.
- Sirve para **mapear** la web, entender su estructura y encontrar **puntos de inter√©s** (por ejemplo, p√°ginas de login, documentos, pol√≠ticas).

## 2) Herramientas populares (muy breve)
- **Burp Suite Spider**: parte de la suite de pruebas web Burp. Mapea contenido y ayuda a encontrar fallos.
- **OWASP ZAP**: alternativa gratuita y de c√≥digo abierto. Tiene un ‚Äúspider‚Äù (ara√±a) para descubrir p√°ginas.
- **Scrapy (Python)**: un **framework** para crear **tus propios** rastreadores y extraer datos.
- **Apache Nutch (Java)**: pensado para **rastreo a gran escala** (muchos dominios, gran volumen).

> Tip: Cada herramienta tiene su estilo. En este documento **usaremos Scrapy + ReconSpider** porque es sencillo de replicar y entender.

## 3) Reglas de oro (√©tica y legalidad)
- **Pide permiso** al due√±o del sitio si no es un laboratorio o tu dominio.
- **No satures** el servidor con demasiadas peticiones.
- Respeta las leyes y los T√©rminos de Servicio.
- En entornos de pr√°ctica (HTB, etc.) sigue las instrucciones del m√≥dulo/laboratorio.

## 4) Tu primer rastreo con Scrapy + ReconSpider

### 4.1. Instalar Scrapy
Necesitas Python 3 y `pip`. En una terminal:
```bash
pip3 install scrapy
```
Esto descarga e instala Scrapy y dependencias.

### 4.2. Descargar ReconSpider
ReconSpider es una **ara√±a** (script) que automatiza el reconocimiento en un dominio de ejemplo (p. ej., `inlanefreight.com` del curso).

```bash
# Descarga el paquete de ReconSpider
wget -O ReconSpider.zip https://academy.hackthebox.com/storage/modules/144/ReconSpider.v1.2.zip

# Extrae el contenido
unzip ReconSpider.zip
```

### 4.3. Ejecutar la ara√±a
Lanza la ara√±a contra el dominio de pr√°ctica (o **tu** dominio con permiso):

```bash
python3 ReconSpider.py http://inlanefreight.com
```
Cambia `inlanefreight.com` por el dominio objetivo **autorizado**.  
La herramienta rastrear√° el sitio y guardar√° los resultados en un archivo JSON llamado **`results.json`** (o similar, seg√∫n versi√≥n).

## 5) ¬øQu√© aparece en `results.json`?
Un ejemplo simplificado de la **estructura** que suele generarse:

```json
{
  "emails": ["lily.floid@inlanefreight.com", "cvs@inlanefreight.com"],
  "links": ["https://www.inlanefreight.com/index.php/offices/"],
  "external_files": ["https://www.inlanefreight.com/wp-content/uploads/2020/09/goals.pdf"],
  "js_files": ["https://www.inlanefreight.com/wp-includes/js/jquery/jquery-migrate.min.js?ver=3.3.2"],
  "form_fields": [],
  "images": ["https://www.inlanefreight.com/wp-content/uploads/2021/03/AboutUs_01-1024x810.png"],
  "videos": [],
  "audio": [],
  "comments": ["<!-- #masthead -->"]
}
```

### ¬øQu√© significa cada cosa?
- **emails**: direcciones de correo encontradas en el contenido p√∫blico.
- **links**: enlaces (URLs) localizados dentro del sitio.
- **external_files**: archivos p√∫blicos (PDFs, docs, etc.).
- **js_files**: ficheros **JavaScript** que usa la web.
- **form_fields**: campos de formularios detectados (usuario, email, etc.).
- **images / videos / audio**: recursos multimedia.
- **comments**: **comentarios HTML** dentro del c√≥digo fuente (a veces dan pistas).

> Con esto puedes **entender la arquitectura** de la web y detectar ‚Äúpuntos de inter√©s‚Äù (p. ej., `/login`, pol√≠ticas, documentaci√≥n, etc.).

## 6) Paso a paso s√∫per corto (resumen)
1. **Instala Scrapy**: `pip3 install scrapy`  
2. **Descarga** ReconSpider: `wget -O ReconSpider.zip ...`  
3. **Extrae**: `unzip ReconSpider.zip`  
4. **Ejecuta**: `python3 ReconSpider.py http://tu-dominio-con-permiso`  
5. **Abre** `results.json` en tu editor y **revisa** cada secci√≥n.

## 7) Siguientes pasos (si quieres avanzar)
- Filtra resultados por **subdominios** (auth., login., accounts.).  
- Mira si hay una carpeta `/.well-known/` (metadatos p√∫blicos est√°ndar).  
- Guarda los hallazgos en un documento: p√°ginas clave, rutas de login, pol√≠ticas, archivos relevantes.  
- Si dominas Python, adapta ReconSpider o crea tu propia ara√±a con **Scrapy** para extraer exactamente lo que te interese.

## 8) Glosario r√°pido
- **Ara√±a (spider)**: programa que recorre p√°ginas y extrae datos.
- **Endpoint**: URL que hace algo concreto (login, API, descargar archivo).
- **Metadatos**: datos **sobre** el sitio (no el contenido principal), √∫tiles para integraciones y an√°lisis.

## 9) Problemas t√≠picos (y soluciones r√°pidas)
- **No tengo Python/pip** ‚Üí Instala Python 3 desde su web oficial o tu gestor de paquetes.
- **Permisos denegados** ‚Üí Aseg√∫rate de tener permiso para rastrear ese dominio.
- **Bloqueos por el sitio** ‚Üí Baja la velocidad de peticiones o respeta `robots.txt` si procede.
- **El JSON est√° vac√≠o** ‚Üí Prueba con otra URL inicial (homepage), revisa tu conexi√≥n, o comprueba que la ara√±a se ejecut√≥ sin errores.

### Recordatorio final
Usa estas t√©cnicas **solo donde est√© permitido** (tus dominios, entornos de laboratorio o con autorizaci√≥n expl√≠cita). El objetivo de estos apuntes es **aprender** y **analizar** informaci√≥n p√∫blica de forma responsable.
